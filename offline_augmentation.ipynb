{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import shutil\n",
    "import logging\n",
    "import time\n",
    "import traceback\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input and output paths\n",
    "input_root = \"/Users/tony/Desktop/coffeebeans_classification/original_dataset\"\n",
    "output_root = \"/Users/tony/Desktop/coffeebeans_classification/balanced_dataset\"\n",
    "augmentation_strength = 1.0  # Augmentation strength, range 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(folder: str) -> int:\n",
    "    \"\"\"\n",
    "    Recursively count the number of images in a folder.\n",
    "    \n",
    "    This function is essential for determining the class imbalance in the dataset.\n",
    "    It supports various image formats commonly used in computer vision tasks.\n",
    "    \n",
    "    Args:\n",
    "        folder (str): Path to the folder containing images.\n",
    "    \n",
    "    Returns:\n",
    "        int: Total number of images in the folder and its subfolders.\n",
    "    \"\"\"\n",
    "    return sum(len([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))])\n",
    "               for _, _, files in os.walk(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(folder: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Recursively get all image paths in a folder.\n",
    "    \n",
    "    This function is crucial for data preprocessing and augmentation tasks,\n",
    "    as it provides a list of all image files that need to be processed.\n",
    "    \n",
    "    Args:\n",
    "        folder (str): Path to the folder containing images.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: A list of full paths to all image files in the folder and its subfolders.\n",
    "    \"\"\"\n",
    "    return [os.path.join(root, f) for root, _, files in os.walk(folder)\n",
    "            for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image: np.ndarray, method: str, strength: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply a specific augmentation method to an image.\n",
    "    \n",
    "    Data augmentation is a crucial technique in machine learning to increase the diversity of the training set,\n",
    "    reduce overfitting, and improve model generalization.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): Input image as a NumPy array.\n",
    "        method (str): Augmentation method to apply ('rotate', 'flip_horizontal', or 'flip_vertical').\n",
    "        strength (float): Augmentation strength, currently not used but can be implemented for more fine-grained control.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Augmented image as a NumPy array.\n",
    "    \"\"\"\n",
    "    if method == 'rotate':\n",
    "        angle = random.choice([90, 180, 270])\n",
    "        rows, cols = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "        image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    elif method == 'flip_horizontal':\n",
    "        image = cv2.flip(image, 1)\n",
    "    elif method == 'flip_vertical':\n",
    "        image = cv2.flip(image, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(input_folder: str, output_folder: str, target_count: int, strength: float) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Augment the dataset until the target count is reached.\n",
    "    \n",
    "    This function implements a balanced augmentation strategy to ensure that\n",
    "    each class has an equal number of samples, which is crucial for training\n",
    "    unbiased machine learning models.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Path to the input folder containing original images.\n",
    "        output_folder (str): Path to the output folder for augmented images.\n",
    "        target_count (int): The desired number of images after augmentation.\n",
    "        strength (float): Augmentation strength, range 0-1.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, List[str]]: A dictionary mapping augmentation methods to lists of augmented image paths.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    original_images = get_image_paths(input_folder)\n",
    "    augmented_images = defaultdict(list)\n",
    "    \n",
    "    # Copy original images\n",
    "    for img_path in original_images:\n",
    "        rel_path = os.path.relpath(img_path, input_folder)\n",
    "        output_path = os.path.join(output_folder, rel_path)\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        shutil.copy2(img_path, output_path)\n",
    "        augmented_images['original'].append(output_path)\n",
    "    \n",
    "    # Perform data augmentation\n",
    "    augmentation_methods = ['rotate', 'flip_horizontal', 'flip_vertical']\n",
    "    while sum(len(images) for images in augmented_images.values()) < target_count:\n",
    "        img_path = random.choice(original_images)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if image is None:\n",
    "            logger.warning(f\"Unable to read image: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        method = random.choice(augmentation_methods)\n",
    "        augmented = augment_image(image, method, strength)\n",
    "        rel_path = os.path.relpath(img_path, input_folder)\n",
    "        output_name = f\"augmented_{method}_{len(augmented_images[method])}_{os.path.basename(rel_path)}\"\n",
    "        output_path = os.path.join(output_folder, os.path.dirname(rel_path), output_name)\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        cv2.imwrite(output_path, augmented)\n",
    "        augmented_images[method].append(output_path)\n",
    "    \n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(input_root: str, output_root: str, strength: float) -> Dict[str, Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Balance the dataset by augmenting underrepresented classes and subcategories.\n",
    "    \n",
    "    This function implements a hierarchical balancing strategy, ensuring that\n",
    "    the dataset is balanced at the class, subclass, and sub-subclass levels.\n",
    "    This is particularly important for multi-level classification tasks and\n",
    "    for maintaining the hierarchical structure of the data.\n",
    "    \n",
    "    Args:\n",
    "        input_root (str): Path to the root folder of the original dataset.\n",
    "        output_root (str): Path to the root folder for the balanced dataset.\n",
    "        strength (float): Augmentation strength, range 0-1.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Tuple[str, str]]: A dictionary mapping class names to tuples of (input_folder, output_folder).\n",
    "    \"\"\"\n",
    "    class_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "    class_folders = {}\n",
    "    \n",
    "    # Count images in each class, subclass, and sub-subclass\n",
    "    for class_name in os.listdir(input_root):\n",
    "        if class_name.startswith('.'): continue  # Skip hidden files/folders\n",
    "        class_path = os.path.join(input_root, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_folders[class_name] = class_path\n",
    "            for subclass_name in os.listdir(class_path):\n",
    "                if subclass_name.startswith('.'): continue  # Skip hidden files/folders\n",
    "                subclass_path = os.path.join(class_path, subclass_name)\n",
    "                if os.path.isdir(subclass_path):\n",
    "                    for sub_subclass_name in os.listdir(subclass_path):\n",
    "                        if sub_subclass_name.startswith('.'): continue  # Skip hidden files/folders\n",
    "                        sub_subclass_path = os.path.join(subclass_path, sub_subclass_name)\n",
    "                        if os.path.isdir(sub_subclass_path):\n",
    "                            count = count_images(sub_subclass_path)\n",
    "                            class_counts[class_name][subclass_name][sub_subclass_name] = count\n",
    "    \n",
    "    # Find the maximum count for the deepest level\n",
    "    max_sub_subclass_count = max(count for class_counts in class_counts.values()\n",
    "                                 for subclass_counts in class_counts.values()\n",
    "                                 for count in subclass_counts.values())\n",
    "    \n",
    "    augmented_classes = {}\n",
    "    \n",
    "    for class_name, subclass_counts in class_counts.items():\n",
    "        class_output_folder = os.path.join(output_root, class_name)\n",
    "        class_input_folder = class_folders[class_name]\n",
    "        try:\n",
    "            for subclass_name, sub_subclass_counts in subclass_counts.items():\n",
    "                for sub_subclass_name, count in sub_subclass_counts.items():\n",
    "                    sub_subclass_input_folder = os.path.join(class_input_folder, subclass_name, sub_subclass_name)\n",
    "                    sub_subclass_output_folder = os.path.join(class_output_folder, subclass_name, sub_subclass_name)\n",
    "                    \n",
    "                    if count < max_sub_subclass_count:\n",
    "                        logger.info(f\"Augmenting {class_name}/{subclass_name}/{sub_subclass_name} from {count} to {max_sub_subclass_count}\")\n",
    "                        augment_dataset(sub_subclass_input_folder, sub_subclass_output_folder, max_sub_subclass_count, strength)\n",
    "                    else:\n",
    "                        logger.info(f\"Copying {class_name}/{subclass_name}/{sub_subclass_name} without augmentation\")\n",
    "                        shutil.copytree(sub_subclass_input_folder, sub_subclass_output_folder, dirs_exist_ok=True)\n",
    "            \n",
    "            augmented_classes[class_name] = (class_input_folder, class_output_folder)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing class {class_name}: {str(e)}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "    \n",
    "    return augmented_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:40:39,212 - INFO - Starting dataset balancing and augmentation process...\n",
      "2024-10-14 14:40:39,218 - INFO - Augmenting defect/dry/medium from 200 to 400\n",
      "2024-10-14 14:40:39,735 - INFO - Augmenting defect/dry/light from 200 to 400\n",
      "2024-10-14 14:40:40,324 - INFO - Augmenting defect/dry/dark from 200 to 400\n",
      "2024-10-14 14:40:40,889 - INFO - Augmenting defect/honey/medium from 200 to 400\n",
      "2024-10-14 14:40:41,275 - INFO - Augmenting defect/honey/light from 200 to 400\n",
      "2024-10-14 14:40:41,664 - INFO - Augmenting defect/honey/dark from 200 to 400\n",
      "2024-10-14 14:40:42,118 - INFO - Augmenting defect/wet/medium from 200 to 400\n",
      "2024-10-14 14:40:42,527 - INFO - Augmenting defect/wet/light from 200 to 400\n",
      "2024-10-14 14:40:42,901 - INFO - Augmenting defect/wet/dark from 200 to 400\n",
      "2024-10-14 14:40:43,265 - INFO - Copying normal/dry/medium without augmentation\n",
      "2024-10-14 14:40:43,425 - INFO - Copying normal/dry/light without augmentation\n",
      "2024-10-14 14:40:43,594 - INFO - Copying normal/dry/dark without augmentation\n",
      "2024-10-14 14:40:43,763 - INFO - Copying normal/honey/medium without augmentation\n",
      "2024-10-14 14:40:43,917 - INFO - Copying normal/honey/light without augmentation\n",
      "2024-10-14 14:40:44,076 - INFO - Copying normal/honey/dark without augmentation\n",
      "2024-10-14 14:40:44,237 - INFO - Copying normal/wet/medium without augmentation\n",
      "2024-10-14 14:40:44,398 - INFO - Copying normal/wet/light without augmentation\n",
      "2024-10-14 14:40:44,561 - INFO - Copying normal/wet/dark without augmentation\n",
      "2024-10-14 14:40:44,732 - INFO - Dataset balancing completed. Final image counts:\n",
      "2024-10-14 14:40:44,732 - INFO - Class: defect\n",
      "2024-10-14 14:40:44,733 - INFO -   Subclass: dry\n",
      "2024-10-14 14:40:44,734 - INFO -     Sub-subclass medium: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,735 - INFO -     Sub-subclass light: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,736 - INFO -     Sub-subclass dark: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,736 - INFO -   Subclass: honey\n",
      "2024-10-14 14:40:44,737 - INFO -     Sub-subclass medium: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,738 - INFO -     Sub-subclass light: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,739 - INFO -     Sub-subclass dark: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,739 - INFO -   Subclass: wet\n",
      "2024-10-14 14:40:44,740 - INFO -     Sub-subclass medium: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,740 - INFO -     Sub-subclass light: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,741 - INFO -     Sub-subclass dark: Original: 200, Augmented: 400\n",
      "2024-10-14 14:40:44,741 - INFO - Class: normal\n",
      "2024-10-14 14:40:44,742 - INFO -   Subclass: dry\n",
      "2024-10-14 14:40:44,743 - INFO -     Sub-subclass medium: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,744 - INFO -     Sub-subclass light: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,745 - INFO -     Sub-subclass dark: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,745 - INFO -   Subclass: honey\n",
      "2024-10-14 14:40:44,747 - INFO -     Sub-subclass medium: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,748 - INFO -     Sub-subclass light: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,749 - INFO -     Sub-subclass dark: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,749 - INFO -   Subclass: wet\n",
      "2024-10-14 14:40:44,750 - INFO -     Sub-subclass medium: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,751 - INFO -     Sub-subclass light: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,752 - INFO -     Sub-subclass dark: Original: 400, Augmented: 400\n",
      "2024-10-14 14:40:44,752 - INFO - Total runtime: 5.54 seconds\n",
      "2024-10-14 14:40:44,753 - INFO - Dataset balancing and augmentation process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Main program\n",
    "try:\n",
    "    start_time = time.time()\n",
    "\n",
    "    logger.info(\"Starting dataset balancing and augmentation process...\")\n",
    "    augmented_classes = balance_dataset(input_root, output_root, augmentation_strength)\n",
    "\n",
    "    # Print final counts for each class, subclass, and sub-subclass\n",
    "    logger.info(\"Dataset balancing completed. Final image counts:\")\n",
    "    for class_name, (original_folder, augmented_folder) in augmented_classes.items():\n",
    "        logger.info(f\"Class: {class_name}\")\n",
    "        for subclass in os.listdir(original_folder):\n",
    "            if subclass.startswith('.'): continue  # Skip hidden files/folders\n",
    "            subclass_path = os.path.join(original_folder, subclass)\n",
    "            if os.path.isdir(subclass_path):\n",
    "                logger.info(f\"  Subclass: {subclass}\")\n",
    "                for sub_subclass in os.listdir(subclass_path):\n",
    "                    if sub_subclass.startswith('.'): continue  # Skip hidden files/folders\n",
    "                    original_sub_subclass_folder = os.path.join(original_folder, subclass, sub_subclass)\n",
    "                    augmented_sub_subclass_folder = os.path.join(augmented_folder, subclass, sub_subclass)\n",
    "                    if os.path.isdir(original_sub_subclass_folder):\n",
    "                        original_count = count_images(original_sub_subclass_folder)\n",
    "                        augmented_count = count_images(augmented_sub_subclass_folder)\n",
    "                        logger.info(f\"    Sub-subclass {sub_subclass}: Original: {original_count}, Augmented: {augmented_count}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    logger.info(f\"Total runtime: {end_time - start_time:.2f} seconds\")\n",
    "    logger.info(\"Dataset balancing and augmentation process completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during execution: {str(e)}\")\n",
    "    logger.error(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
